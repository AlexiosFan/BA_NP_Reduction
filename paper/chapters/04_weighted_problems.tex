\chapter{Weighted Sum Problems}\label{chapter:weighted}
In this chapter, we discuss the NP-Hardness of a few weighted sum problems. In weighted sum problems, 
there is a weighting function $w$ over a set $S$. The problems ask about whether the weight of elements 
in $S$ satisfies an equality or inequality relationship. The weighted sum problems are also mathematical programming 
problems, which is another large discipline of NP-hard problems. In Karp's paper, there were Partition, Subset Sum \footnote{What Karp presented was referred to as Knapsack, although
the definition is closer to the Subset Sum nowadays}, and Knapsack introduced. 
We present reductions from Exact Cover to Subset Sum, from Subset Sum to Partition, Knapsack and Zero-one Integer Programming. 

\section{Subset sum}
We define Subset Sum with a set and a weighting function. There is also an alternative definition using a multiset or a sequence without 
a weighting function, which is useful for other reductions in this work. More details follow in the \hyperref[sec:partition]{Partition} section. 
\problem{Subset Sum}{A finite set $S$, a weighting function $w$, and an integer $B$}{Is there a subset $S' \subseteq S$ s.t. 
\begin{equation}
    \sum_{x \in S'} w(x) = B \tag{1}
\end{equation}}
\begin{myalign}
    \textbf{Subset Sum} := \{(S, w, B) | \exists S' \subseteq S. \sum_{x \in S'} w(x) = B\}
\end{myalign}

\subsection{Reduction Details}
We reduce Exact Cover to Subset Sum. We start with Exact Cover problems over natural numbers. 
Given $(X, S)$ an instance of Exact Cover over natural numbers, let $S$ be the set in the instance of Subset Sum. Then we
define the weighting function $w_{p}$ and the sum $B_{X}$ by 
\begin{align*}
    w_p(s) = \sum_{x \in s} p^x , B_X = w(X)
\end{align*}
where $p$ is a natural number no less than $|S|$
\begin{definition}[Reduction XC to SS]
    Given an instance of Exact Cover over natural numebers $(X, S)$, 
    it is reduced to an instance of Subset Sum $(S, w_p, B_X)$ as presented above.
\end{definition}
With this definition, we show the correctness of the reduction.
\begin{lemma}[Soundness]
    If $(X, S)$ is an instance of Exact Cover. The reduced $(S, w_p, B_X)$ is then an instance of Subset Sum. 
\end{lemma}
\begin{proof}
    Let the $S' \subseteq S$ be an exact cover of X. It then holds that
\begin{align*}
    \sum_{s \in S'} w_p(s) = \sum_{s \in S'} (\sum_{x \in s} p^x) 
    \stackrel{\text{S' disjoint}}{=} \sum_{x \in \bigcup S'} p^x 
    \stackrel{X = \bigcup S'}{=} \sum_{x \in X} p^x = B_X
\end{align*}
Thus, $(S, w_p, B_X)$ is an instance of Subset Sum. 
\end{proof}
\begin{lemma}[Completeness]
    Let $(S, w_p, B_X)$ be reduced from $(X, S)$. If $(S, w_p, B_X)$ is an instance of Subset Sum, 
    $(X, S)$ has to be an instance of Exact Cover. 
\end{lemma}
\begin{proof}
    \label{lemma:sscompl}
    Obtain $S' \subseteq S$ for which \textbf{(1)} holds. We show the disjointness of $S'$ by contradiction. 
Assume that $S'$ is not disjoint. Then there exist $s_1, s_2 \in S'$ s.t. $s_1 \cap s_2 \not= \emptyset$. Let $a \in s_1 \cap s_2$ be arbitrary. Then 
there are two cases for the coefficient $c_a$ of $p^a$ in the polynomial $\sum_{x \in S'} w_p(x)$ of $p$. 
\begin{enumerate}
    \item $c_a \neq 1$. This case is invalid. It is obvious that the $p$-nary representation of 
    a natural number is unique. Since \textbf{(1)} holds and $B_X = \sum_{x \in X} {p^x}$, the coefficient 
    $c_a$ has to be exactly one.
    \item $c_a = 1$. Though \textbf{(1)} is satisfied, there are still at least two $p^a$ in the polynomial $\sum_{x \in S'} w_p(x)$.
    One of them stems from $s_1$, the other from $s_2$.
    Hence the number of $p^a$ in this polynomial is at least $p$. However, there are utmost $|S|$ elements in $S'$, meaning that there are utmost $|S|$ such $p^a$. From the 
    fact the $p > |S|$, it is not possible that the number of $p^a$ is greater equal $p$. As a result, this case is also invalid.
\end{enumerate}
In conclusion, the assumption is false, and $S'$ is disjoint. Then, it follows directly from the disjointness that $S'$ covers $X$ exactly, otherwise \textbf{(1)}
is not satisfied.
\end{proof}
This reduction is, however, limited to the Exact Cover over natural numbers. It is still necessary to generalize the reduction. 
For this reason, we need to construct a mapping.
\begin{lemma}
    \label{lemma:9}
    Let $S$ be an arbitrary finite set. Then there exists a bijective function $f, S \rightarrow N$ s.t. 
    \begin{align*}
        f(S) = \begin{cases}
            \emptyset & S = \emptyset \\ 
            \{0, 1, ..., |S| - 1\} & \text{otherwise}
        \end{cases}
    \end{align*}
\end{lemma}
\begin{proof}
    Trivial.
\end{proof}
With this approach, we are able to generalize Exact Cover and covert each instance to an equivalent instance 
over natural numbers. 
\begin{definition}[Reduction XC to SS, updated]
    Given an instance of Exact Cover $(X, S)$, 
    we first map it into natural numbers using the bijective function $f$. 
    The resulting instance of Exact Cover $(X_f, S_f)$ is reduced to an instance of Subset Sum $(S_f, w_p, B_X)$ as presented above.
\end{definition}
Then, we perform a complexity analysis over the whole construction.
\begin{lemma}[Polynomial Complexity]
    The construction of $(S_f, w_p, B_X)$ from $(X, S)$ can be computed within polynomial time. 
\end{lemma}
\begin{proof}
    When we map an arbitrary set into a natural number set as presented in Lemma 9, we have to iterate over the set $X$, which costs the complexity of $|X|$. 
Furthremore, we have to iterate $S$ to construct $w_p$ and $B_X$, resulting in the complexity of $2|S|$. In total, it costs $|X| + 2|S| \in\bigO{|X| + |S|}$, 
i.e. the linear complexity. 
\end{proof}
Finally, we summarize to obtain the main theorem.
\begin{theorem}
    Subset Sum is NP-hard.
\end{theorem}

\subsection{Implemantation Deatails}
The Isabelle definition of Subset Sum is given in \hyperref[fig:4.1]{Figure 4.1}. 
It is easy to notice that the definition is identical to the pen-and-paper definition.
\begin{figure}[!h]
    \Snippet{subset-sum-def}
    \caption{Definition of Subset Sum}
    \label{fig:4.1}
\end{figure}
\subsubsection{Definition of the Reduction}
In implementation shown in \hyperref[fig:4.2]{Figure 4.2}, we started with the construction as presented in \hyperref[lemma:9]{Lemma 9}. The function \textbf{map\_to\_nat} returns 
a mapping function with the property in Lemma 9, in whose definition the predicate \textbf{SOME} is used again.
Following this, we define the weighting function and reduction function. 
Similar to what happened to Exact Hitting Set, we also check if $X$ is finite and if $S$ is 
a collection before we perform a reduction, for these conditions are a requirement under our definition. 
\begin{figure}[!h]
    \Snippet{subset-sum-red}
    \caption{Definition of the reduction, XC to SS}
    \label{fig:4.2}
\end{figure}
Apart from the definition, we need a lemma that converts the sum to a polynomial. To guarantee that $p^k$ is unique for an arbitrary $k$, 
we require that $p \geq 2$ as in \hyperref[fig:4.3]{Figure 4.3}.
\begin{figure}[!h]
    \Snippet{subset-sum-aux1} 
    \caption{Definition of the reduction, XC to SS}
    \label{fig:4.3}
\end{figure}

\subsubsection{Uniqueness of Polynomials}
The main part of the proof is implemented as discussed in the reduction details. A problem occurred when showing the completeness of the reduction. 
Besides the proof presented in the implementation details, it is necessary to show that the representation of a natural number as
polynomial with the base $p$ is unique. To achieve this, we imported the Archive of Formal Proofs entry DigitInBase and applied the theorem \textbf{seq\_uniqueness}
in \hyperref[fig:4.4]{Figure 4.4}.\\\\
$m$ is computed by $\sum \textbf{D j} \cdot b^i$, hence \textbf{D j} should be exactly the $i$-th 
digit of $m$ with base $b$, i.e. $\textbf{D j} = \textbf{ith\_digit m j}$. 
In our proof by contradiction as in \hyperref[lemma:sscompl]{Lemma 8}, 
we found an $m = \sum_{x \in S'} w(x) = B$ that can be represented with two coefficient functions \textbf{D j} and \textbf{E j}. 
\textbf{D j} is a representation resulting from $\sum_{x \in S'} w(x)$, 
while \textbf{E j} is a representation resulting from $B$.
Hence it holds that 
\begin{align*}
    \textbf{D j} = \textbf{ith\_digit m j} = \textbf{E j}
\end{align*}
However, due to the existence of $a \in s_1 \cap s_2$, it holds that $\textbf{D a} \geq 2$ and $\textbf{E a} = 1$ in the meantime. 
By this contradiction, we are able to show the completeness.
\begin{figure}[!h]
    \Snippet{subset-sum-aux2}
    \caption{Snippets from DigitInBase}
    \label{fig:4.4}
\end{figure}
\subsubsection{Polynomial-time Complexity}
The implementation of the proof for polynomial complexity is identical to what is introduced in reduction details. 
Fortunately, the proof is automated, hence we only present and discuss about complexity in \hyperref[fig:4.5]{Figure 4.5} and \hyperref[table:4.1]{Table 4.1}.
Different from the previous reductions, this reduction returns not only a set but also two constants,
resulting a few constant operations during the reduction. Overall, the reduction has linear complexity,
which is the same as the pen-and-paper proof.
\begin{figure}[!h]
    \Snippet{subset-sum-poly}
    \caption{The NREST version of the reduction, XC to SS}
    \label{fig:4.5}
\end{figure}
\begin{table}[!h]
    \centering
    \begin{tabular}{| c | c | c |}
        \hline 
        Operation & Functionality & Complexity \\ 
        \hhline{|=|=|=|}
        mop\_check\_finite\_collection & checking the requirements & $1$ \\ 
        \hline
        mop\_constr\_bij\_mapping & constructing the mapping & $3n + 1$ \\ 
        \hline
        mop\_constr\_base & computing the base of polynomials & $n + 3$ \\ 
        \hline
        mop\_constr\_weight & constructing the weighting function & $1$\\ 
        \hline
        mop\_constr\_B & computing the constant sum & $3n + 1$ \\
        \hline
    \end{tabular}
    \caption{Complexity of operations in reduction XC to SS.}
    \label{table:4.1}
\end{table}

\subsection{Example}
Again, we present an example for the reduction from Exact Cover to Subset Sum for better understanding.\\\\
\textbf{Input:} The instance of exact cover is given by 
\begin{align*}
    X &:= \{1, 2, 3, 4\} \\ 
    S &:= \{\{1\}, \{2\}, \{2, 3\}, 
    \{2, 4\}, \{3, 4\}, \{1, 2, 3\}\}
\end{align*}
\textbf{Output:} 
While $S$ is not changed, the weighting function $w$ and the sum $B$ is given by 
\begin{align*}
    w_p(s) = \sum_{x \in s} 4^x,
    B_X = w(X) = 4 + 4^2 + 4^3 + 4^4 = 340
\end{align*}
\textbf{Validity:} An exact cover $S'$ is given by 
\begin{align*}
    S' = \{\{1\}, \{2\}, \{3, 4\}\}
\end{align*}
Hence it holds that 
\begin{align*}
    w(\{1\}) + w(\{2\}) + w(\{3,4\}) = 4 + 4^2 + (4^3 + 4^4) = 340 = B
\end{align*}

\section{Subset Sum in Sequence and Partition}\label{sec:partition}
The next problem that we want to reduce to is Partition. 
For convenience, we use $as - as'$ to demonstrate the difference between two sequences.
\begin{align*}
    as - as' = \{x | x \in as \land x \not\in as' \}
\end{align*}
\problem{Partition}{A finite sequence $as$ of natural numbers.}{Is there a sub-sequence $as' \subset s$ s.t. 
\begin{align*} 
    \sum_{x \in as'} x = \sum_{x \in  as - as'} x \tag{2}
\end{align*}
}
\begin{myalign}
    \textbf{Partition} := \{(a_1, a_2,...,a_n) | \exists S' \subseteq \{1, ..., n\}. \sum_{j \in S'} a_j = \sum_{j \not\in S'} a_j\}
\end{myalign}

\subsection{Reduction Details}
Since all of the valid inputs require the sequences to be finite, we model the sequences using lists in all implementations.
In addition, $\#$ is used to append elements at the front of the lists. Although it is possible 
to define the partition problem using the set and weighting function as in Subset Sum.
We choose the presented definition for two reasons.
\begin{enumerate}
    \item Showing that the definition of the problem is not an important factor 
    in reduction, i.e. both definitions are valid and reducible under Isabelle.
    \item Being consistent with the available Archive of Formal Proof instance 
    \textit{Hardness of Lattice Problems} \cite{CVP_Hardness-AFP}, which is also the purpose of this work,
    i.e. providing theoretical basis for other verification projects.
\end{enumerate} 
Thus, we need to perform the reduction from the sequence version of Subset Sum. 
We give the definition of Subset Sum using a sequence. 
\problem{Subset Sum in Sequence}{
    A finite natural number sequence $as$, a natural number $s$}{
    Is there a sub-sequence $as' \subset as$ s.t. 
    \begin{align*}
        \sum_{x \in as'} x = B \tag{3}
    \end{align*}
}
\begin{myalign}
    \textbf{Subset Sum Seq} := \{(a_1, a_2,...,a_n, s) | \exists S' \subseteq \{1, ..., n\}. \sum_{j \in S'} a_j = s\}
\end{myalign}
Given the instance of Subst Sum $(S, w, B)$, it is obvious that we can obtain a sequence $as$ by
converting $S$ into a sequence and map the sequence with the weighting function $w$. Let $s = B$.
The resulting pair $(as, s)$ is then an instance of the Subset Sum problem in sequence representation. 
Then we reduce $(as, s)$ to an instance of Partition $bs$.
\begin{align*}
    bs = (1 - s + \sum_{x \in as} x) \# (s + 1) \# as
\end{align*}
With this definition, we start to show the soundness of the reduction.
\begin{lemma}[Soundness]
    If there exists an $as'$ s.t. the equation \textbf{(3)} holds for $(as, B)$, \textbf{(2)} should hold for the reduced $bs$.
\end{lemma}
We construct a $bs'$ from $as'$ by 
\begin{proof}
    \begin{align*}
        bs' &= (1 - s + \sum_{x \in as} x) \# as' \\
        bs - bs' &=  (s + 1) \# (as - as')
    \end{align*}
    Where the sums of the sequences satisfy the equation 
    \begin{align*}
        \sum_{x \in bs'} x = (1 - s + \sum_{x \in as} x) + \sum_{x \in as'} x
        = (1 - s + \sum_{x \in as} x) + s = (s + 1) + (\sum_{x \in as} x - s)
        = \sum_{x \in bs - bs'}
    \end{align*}
    Thus, the reduction is sound.
\end{proof}
Similarly, we can show the completeness of the reduction.
\begin{lemma}[Completeness]
    Let $bs$ be reduced from $(as, B)$. If there exists a $bs'$ s.t. \textbf{(2)} holds for $bs$, 
    \textbf{(3)} should then hold for $(as, B)$.
\end{lemma}
\begin{proof}
    It holds that
\begin{align*}
    (1 - s + \sum_{x \in as} x) + (s + 1) = 2 + \sum_{x \in as} x > \sum_{x \in as} x
\end{align*}
As a result, $(1 - s + \sum_{x \in as} x)$ and $s + 1$ are not supposed be simultaneously existent in $bs'$. 
After separating the first two elements of bs into different subsequences, the $as'$ is constructed 
by obtaining the tail of $bs'$, with which the completeness is proven.
\end{proof} 
Finally, we analyse the complexity of the reduction.
\begin{lemma}[Polynomial Complexity]
    The reduction from Subset Sum to Partition can be computed within polynomial time.
\end{lemma}
\begin{proof}
The conversion between the definitions of the Subset Sum problem costs the complexity of $|S| + 1$,
for it it necessary to iterate the set $S$ and map the sequence with the weighting function. Furthermore, we iterate the sequence similary when reducing the subset sum to partition, costing
the complexity of $|as| + 2$. In total, the complexity is $(|S| + 1) + (|as| + 2) \in \bigO{|S|}$  because of $|as| = |S|$.
Thus, the reduction has linear complexity.
\end{proof}
Then, we conclude the the main theorem with all the lemmas proven.
\begin{theorem}
    Partition is NP-hard.
\end{theorem}
\subsection{Implemantation Details of Subset Sum in Sequence}
\subsubsection*{Intermediate Step}
Although the reduction is more straightforward compared to the previously introduced ones, the implementation is even lengthier. 
The reason is that conversion of the set to a list also needs an additional reduction for indexing. For this reason, we introduce 
a intermediate step, \textbf{subset\_sum\_indices} in \hyperref[fig:4.5]{Figure 4.5}.
Apparently, to map $S$ to an set of integers from 1 to $|S|$, we need to apply \hyperref[lemma:9]{Lemma 9} again. 
As always, we have to check if $S$ is finite, because finiteness is a requirement of the reduction.
\begin{figure}[!h]
    \Snippet{ss-indices-def}
    \caption{Intermediate step of the reduction I, SS to Part}
    \label{fig:4.6}
\end{figure}\\\\
Then, it suffices to convert the set into a list and perform the mapping, in which we used the function 
\textbf{sorted\_list\_of\_set}, converting a set of ordered type to a sorted list. Similarly, we check if 
$S$ is finite and if $S$ is of form $\{1, 2, .. , |S|\}$ as a requirement. The proof for the correctness is then mostly straightforward
after unfolding the necessary definitions and using a few available lemmas in the list library, such as \textbf{nth\_equalityI} etc. 

\subsubsection*{Polynomial-time Complexity}
Similar to the reduction from Exact Cover to Subset Sum, the proof of the polynomial-time complexity for two reductions 
is rather trivial. An NREST version of the reduction is given in \hyperref[fig:4.7]{Figure 4.7}.
As shown in \hyperref[table:4.2]{Table 4.2} and \hyperref[table:4.3]{Table 4.3}, the reduction 
costs linear-time complexity. Similar to the reduction from Exact Cover to Subset Sum, there are a few 
constant steps taken because of the structure of the instances.
\begin{figure}[!h]
    \Snippet{ss-indices-poly}
\Snippet{ss-list-poly}
\caption{The NREST version of the reductions, SS to SS list}
\label{fig:4.7}
\end{figure}
\begin{table}[!h]
    \centering 
    \begin{tabular}{| c | c | c |}
        \hline 
        Operation & Functionality & Complexity \\ 
        \hhline{|=|=|=|}
        mop\_check\_finiteness & checking the requirements & $1$ \\ 
        \hline 
        mop\_mapping\_of\_set & constructing the mapping & $6n + 1$ \\ 
        \hline 
        mop\_updating\_the\_weighting & updating the weighting function & $6n + 1$ \\ 
        \hline 
    \end{tabular}
    \caption{Complexity of operations in reduction SS to SS Indices.}
    \label{table:4.2}
\end{table}
\begin{table}[!h]
    \centering 
    \begin{tabular}{| c | c | c |}
        \hline 
        Operation & Functionality & Complexity \\ 
        \hhline{|=|=|=|}
        mop\_check\_finiteness\_set & checking the requirements & $1$ \\ 
        \hline 
        mop\_mapping\_to\_list & mapping the set to the list & $6n$ \\ 
        \hline 
        mop\_nat\_to\_int & computing the constant & $1$ \\ 
        \hline 
    \end{tabular}
    \caption{Complexity of operations in reduction SS Indices to SS List.}
    \label{table:4.3}
\end{table}

\subsection{Implemantation Details of Partition}
\subsubsection{Choice of Definitions}
Instead of the original definition, where the sum of a sub-sequence is equal to its complement, we use a different definition in the implementation,
where the double of the sum of a sub-sequence is equal to to the sum of the whole sequence. We have also shown that this definition is equivalent 
to the original definition, i.e. \textbf{part\_alter} in \hyperref[fig:4.8]{Figure 4.8}. 
\begin{figure}[!h]
    \Snippet{part-def}
    \caption{Definitions for Partition}
    \label{fig:4.8}
\end{figure}\\\\
The reason was initially the convenience of the proof. 
In \textbf{part\_alter}, it is necessary to consider the sum of the sub-sequence $(as - as')$ when showing the soundness lemma. 
Unfortunately, this is rather complex under our definition, for we have to flip the list $xs$, the zero-one list that is used for multiplication. For this 
flipping operation, we have shown the lemma \textbf{sum\_binary\_part} in \hyperref[fig:4.9]{Figure 4.9}. If we use the new definition, this is avoidable.
\begin{figure}[!h]
    \Snippet{part-aux1}
    \caption{Details of the reduction, SS List to Partition}
    \label{fig:4.9}
\end{figure}
However, when showing the completeness lemma, we found out that we have to show the same statement for the new definition, too. 
Thus, it is not an absolutely better definition. 
\subsubsection{Polynomial-time Complexity}
The proof of the polynomial-time complexity is also trivial. 
An NREST version is given in \hyperref[fig:4.10]{Figure 4.10}. 
As shown in \hyperref[table:4.5]{Table 4.5}, the reduction costs linear complexity. It is slightly 
different from the estimation of the pen-and-paper proof, because a few more constance steps are taken. 
\begin{figure}[!h]
    \Snippet{part-poly}
    \caption{The NREST version of the reductions, SS List to Partition}
    \label{fig:4.10}
\end{figure}
\begin{table}[!h]
    \centering 
    \begin{tabular}{| c | c | c |}
        \hline 
        Operation & Functionality & Complexity \\ 
        \hhline{|=|=|=|}
        mop\_check\_not\_greater\_eq & checking the requirements & $1$ \\ 
        \hline 
        mop\_cons\_new\_sum & constructing the new sequence & $2n + 5$ \\ 
        \hline 
    \end{tabular}
    \caption{Complexity of operations in reduction SS List to Partition.}
    \label{table:4.5}
\end{table}

\subsection{Example}
As a last part of Partition, we present an example indicating how an instance of Subset Sum 
is reduce to an instance of Partition.\\
\textbf{Input:} We use the same instance of subset sum as in the previous example. $(S, w, B)$ be 
then converted to 
\begin{align*}
    as &:= [4, 16, 80, 272, 320, 72] \\ 
    s &:= 340
\end{align*}
\textbf{Output:} The reduced $bs$ is then 
\begin{align*}
    bs := [425, 341, 4, 16, 80, 272, 320, 72]
\end{align*}
\textbf{Validity:} With $as' = [4, 16, 320]$, the corresponding $bs'$ is 
\begin{align*}
    bs' = [425, 4, 16, 320] \\ 
    bs - bs' = [341, 80, 272, 72]
\end{align*}
with the equality
\begin{align*}
    425 + 4 + 16 + 320 = 765 = 341 + 80 + 272 + 72 
\end{align*}

The other reductions are easier to understand, hence no example is provided here.

\section{Knapsack and Zero-One Integer Programming}
Knapsack and Zero-One Integer Programming are another two classical weighted sum problems. While Subset Sum was referred 
to as Knapsack in Karp's paper, its definition is nowadays different. Additionally, Zero-One Integer Programming 
was originally reduced from Satisfiability. Nevertheless, there exist trivial reductions from Subset Sum to both of the problems. Thus, 
we include them in this chapter and present a reduction for them each. 
Since the reductions and definitions are nicely chosen, the implementation was identical to pen-and-pencil proof 
and largely automated. Hence a discussion for implementation details is omitted for these problems.

\subsection{Knapsack}
\problem{Knapsack}{A finite set S, a weighting function $w$, a limiting function $b$, a upperbound $W$, a lowerbound $B$}{
    Is there a subset $S' \subseteq S$ s.t. 
    \begin{align*}
        \sum_{x \in S'} w(x) &\leq W \\ 
        \sum_{x \in S'} b(x) &\geq B \tag{4}
    \end{align*}
}
We reduce Subset Sum to Knapsack. With $(S, w, B)$ as an instance of Subset Sum, $(S, w, w, B, B)$
is then an instance of knapsack.
\begin{theorem}[Polynomial-time Reduction]
    Knapsack is NP-hard.
\end{theorem}
\begin{proof}
    Trivially, it holds that 
    \begin{align*}
        \sum_{x \in S'} w(x) &= W \\ 
        \sum_{x \in S'} b(x) &= B
    \end{align*}
    where $b = w$ and $W = B$. Thus, equations in \textbf{(4)} are satisfied.
    Apparently, the reduction is constant, for all operations are constant. 
\end{proof}

\subsection{Zero-one Integer Programming}
\problem{Zero-one Integer Programming}{A finite set $X$ of pairs $(x, b)$, where $x$ is an $m$-tuple of integers and $b$
is an integer, an $m$-tuple $c$ and an integer $B$}{
    Is there an $m$-tuple $y$ of integers s.t.
    \begin{align*}
        x^T \cdot y &\leq b \\ 
        c^T \cdot y &\geq B, \forall (x, b) \in X \tag{5}
    \end{align*}
}
Although most researchers tend to use matrix for the 
definition of the zero-one integer programming, we follow the definition from \textit{Computers and Intractability} \cite{garey1979computers}, because 
it is convenient for our definition and consequently requires less effort. Given an instance of subset sum problem in sequence,
(as, s), let 
\begin{align*}
    X = \{(as, s)\}, c = as, B = s
\end{align*} 
The triple $(X, c, B)$ is then an instance of Zero-One Integer Programming.
\begin{theorem}[Polynomial-time Reduction]
    Zero-One Integer Programming is NP-hard.
\end{theorem}
\begin{proof}
    $(X, c, B)$ is then an instance of the zero-one integer programming problem,
    for there exists an $xs$ s.t. $xs^T \cdot as = s$. Hence all equations in \textbf{(5)} hold.
    Since all the operations are constant, the resulting complexity is also constant.
\end{proof}
It is not hard to notice that this definition can be converted to an alternative definition using matrices. 
The function \textbf{sorted\_list\_of\_set} from the list library may be useful here. 
We did not apply and use this feature, but present it as a possibility, 
in case other reductions in the future are based on the alternative definition with matrices.
